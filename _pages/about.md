---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

{% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %}

<span class='anchor' id='about-me'></span>

Hi! I am Shengjie Luo, a third-year PhD student at Peking University, advised by [Prof.Liwei Wang](http://www.liweiwang-pku.com/) and [Prof.Di He](https://dihe-pku.github.io/). Before that, I finished my undergraduate study at ShenYuan Honors College in Beihang University, majoring in Computer Science.

My main research area lies in machine learning, with special interests in models and algorithms inspired by theoretical insights. Recently, I am focusing on designing expressive, efficient and effective Transformers and Graph Neural Networks with applications in Graph Learning, AI for Science and Natural Language Processing. I have published several papers <a href='https://scholar.google.com/citations?user=ImWO7WYAAAAJ'><img src="https://img.shields.io/endpoint?url={{ url | url_encode }}&logo=Google%20Scholar&labelColor=f6f6f6&color=9cf&style=flat&label=citations"></a>) and been reviewers at the top AI conferences such as NeurIPS, ICML and ICLR.

If you are interested in collaborating with me or want to have a chat, always feel free to contact me through e-mail or WeChat :)



# üî• News
- *2022.09*: One paper is accepted at NeurIPS 2022! 
- *2021.09*: Two papers are accepted at NeurIPS 2021!
- *2021.06*: Graphormer won the 1st place in [PCQM4M Track, OGB Large-Scale Challenge, KDD CUP 2021](https://ogb.stanford.edu/kddcup2021/results/#awardees-of-pcqm4m-lsc-track-leaderboard)!
- *2021.05*: One paper is accepted at ICML 2021!

# üìù Publications 

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">CVPR 2016</div><img src='images/500x300.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Your Transformer May Not be as Powerful as You Expect](https://arxiv.org/abs/2205.13401)

**Shengjie Luo\* **, Shanda Li, Shuxin Zheng, Tie-Yan Liu, Liwei Wang

[**Project**](https://scholar.google.com/citations?view_op=view_citation&hl=zh-CN&user=ImWO7WYAAAAJ&citation_for_view=ImWO7WYAAAAJ:_FxGoFyzp5QC)<strong><span class='show_paper_citations' data='ImWO7WYAAAAJ:_FxGoFyzp5QC'></span></strong>
- TBA. 
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">CVPR 2016</div><img src='images/500x300.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Your Transformer May Not be as Powerful as You Expect](https://arxiv.org/abs/2205.13401)

**Shengjie Luo\* **, Shanda Li, Shuxin Zheng, Tie-Yan Liu, Liwei Wang

[**Project**](https://scholar.google.com/citations?view_op=view_citation&hl=zh-CN&user=ImWO7WYAAAAJ&citation_for_view=ImWO7WYAAAAJ:_FxGoFyzp5QC)<strong><span class='show_paper_citations' data='ImWO7WYAAAAJ:_FxGoFyzp5QC'></span></strong>
- TBA. 
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">CVPR 2016</div><img src='images/500x300.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Your Transformer May Not be as Powerful as You Expect](https://arxiv.org/abs/2205.13401)

**Shengjie Luo\* **, Shanda Li, Shuxin Zheng, Tie-Yan Liu, Liwei Wang

[**Project**](https://scholar.google.com/citations?view_op=view_citation&hl=zh-CN&user=ImWO7WYAAAAJ&citation_for_view=ImWO7WYAAAAJ:_FxGoFyzp5QC)<strong><span class='show_paper_citations' data='ImWO7WYAAAAJ:_FxGoFyzp5QC'></span></strong>
- TBA. 
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">CVPR 2016</div><img src='images/500x300.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Your Transformer May Not be as Powerful as You Expect](https://arxiv.org/abs/2205.13401)

**Shengjie Luo\* **, Shanda Li, Shuxin Zheng, Tie-Yan Liu, Liwei Wang

[**Project**](https://scholar.google.com/citations?view_op=view_citation&hl=zh-CN&user=ImWO7WYAAAAJ&citation_for_view=ImWO7WYAAAAJ:_FxGoFyzp5QC)<strong><span class='show_paper_citations' data='ImWO7WYAAAAJ:_FxGoFyzp5QC'></span></strong>
- TBA. 
</div>
</div>

# üéñ Honors and Awards
- *2021.06* 1st place Winner of PCQM4M Track, OGB Large Scale Challenge, KDD CUP 2021.
- *2018.12* National Scholarship (Top 1%). 

# üìñ Educations
- *2022.09 - 2025.07 (expected)*, PhD Student, School of Intelligence Science and Technology, Peking University.
- *2020.09 - 2022.07*,            Master Student, Academy for Advanced Interdisciplinary Studies, Peking University. 
- *2016.09 - 2020.07*,            Undergraduate Student, Shenyuan Honors College, Beihang University. 

# üí¨ Invited Talks
- *2022.03*, Huawei Technologies Noah's Ark Lab, Stable, Fast and Accurate: Kernelized Attention with Relative Positional Encoding.
- *2022.02*, AI Time, Stable, Fast and Accurate: Kernelized Attention with Relative Positional Encoding. \| [\[media\]](https://mp.weixin.qq.com/s/EjPEwcvbl0xWAmjeVbPpNg) 

# üíª Internships
- *2021.12 - now*,     Machine Learning Group, Microsoft Research Asia, China.
- *2020.10 - 2021.06*, Machine Learning Group, Microsoft Research Asia, China.
- *2019.10 - 2020.06*, Natural Language Computing Group, Microsoft Research Asia, China.
